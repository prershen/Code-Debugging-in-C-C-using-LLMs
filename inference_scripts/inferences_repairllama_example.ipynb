{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3dHE69BUvRrL","executionInfo":{"status":"ok","timestamp":1732601187132,"user_tz":480,"elapsed":1472,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}},"outputId":"849e6d01-4d95-4f52-b173-9a93d566eaf4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install peft\n","!pip install --upgrade bitsandbytes"],"metadata":{"id":"dvf5OU8Xf8yn","executionInfo":{"status":"ok","timestamp":1732601197183,"user_tz":480,"elapsed":10054,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}},"outputId":"7b984ef4-3b8a-4aa2-bec3-f8c35628ad13","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.46.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.6)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.20.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8bgfNpP1fuwR","executionInfo":{"status":"ok","timestamp":1732601214286,"user_tz":480,"elapsed":17107,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}}},"outputs":[],"source":["import json\n","from typing import Optional\n","from dataclasses import dataclass, field\n","from pathlib import Path\n","\n","import torch\n","import transformers\n","from peft import PeftModel\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    GenerationConfig,\n","    HfArgumentParser,\n","    BitsAndBytesConfig,\n",")\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"TVtWXwSZfuwU","executionInfo":{"status":"ok","timestamp":1732601214287,"user_tz":480,"elapsed":7,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}}},"outputs":[],"source":["# If you need to use a specific GPU, you can set it here\n","# if torch.cuda.is_available():\n","#     # Set GPU:1 as the device\n","#     torch.cuda.set_device(1)\n","#     print(f\"Using GPU: {torch.cuda.current_device()}\")\n","# else:\n","#     print(\"CUDA is not available.\")\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":5,"metadata":{"id":"sgKN1roofuwV","executionInfo":{"status":"ok","timestamp":1732601290620,"user_tz":480,"elapsed":76339,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}},"colab":{"base_uri":"https://localhost:8080/","height":187,"referenced_widgets":["84e5d9fe4311446b81df0aab813957c4","a83431d2a90b45e1a21f5093c40f247e","c4b9c53214f2462b90d5e1208b04789d","a3c4729895cf415ab63a6c128690526d","a6376f589205417788300744b52c6386","500cb46e6dd84877916c540b9cd4cee3","1131134d936241698dc62d461fadeb43","aa8bea870bb14817bc82e2cec9532e78","1287cb0feb6344e5a54df94db285eac2","81a847a92b3a4b66836ac329062b29a3","b2b3b591220d497b9d670f987938fd1c"]},"outputId":"472f2455-5af3-4e98-a7ed-702cab795a7c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84e5d9fe4311446b81df0aab813957c4"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\", trust_remote_code=True)\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"codellama/CodeLlama-7b-hf\",\n","    torch_dtype=torch.float16,\n","    # load_in_8bit=True,\n","    trust_remote_code=True,\n","    quantization_config=BitsAndBytesConfig(\n","        load_in_8bit=True,\n","        llm_int8_threshold=6.0\n","    ),\n",")"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"FTsAb_mFfuwV","executionInfo":{"status":"ok","timestamp":1732606824816,"user_tz":480,"elapsed":301,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"60b3a866-5e0b-4b88-a27e-e32f5d21c548"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): PeftModelForCausalLM(\n","      (base_model): LoraModel(\n","        (model): PeftModelForCausalLM(\n","          (base_model): LoraModel(\n","            (model): LlamaForCausalLM(\n","              (model): LlamaModel(\n","                (embed_tokens): Embedding(32016, 4096)\n","                (layers): ModuleList(\n","                  (0-31): 32 x LlamaDecoderLayer(\n","                    (self_attn): LlamaSdpaAttention(\n","                      (q_proj): lora.Linear8bitLt(\n","                        (base_layer): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n","                        (lora_dropout): ModuleDict(\n","                          (default): Dropout(p=0.05, inplace=False)\n","                        )\n","                        (lora_A): ModuleDict(\n","                          (default): Linear(in_features=4096, out_features=8, bias=False)\n","                        )\n","                        (lora_B): ModuleDict(\n","                          (default): Linear(in_features=8, out_features=4096, bias=False)\n","                        )\n","                        (lora_embedding_A): ParameterDict()\n","                        (lora_embedding_B): ParameterDict()\n","                        (lora_magnitude_vector): ModuleDict()\n","                      )\n","                      (k_proj): lora.Linear8bitLt(\n","                        (base_layer): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n","                        (lora_dropout): ModuleDict(\n","                          (default): Dropout(p=0.1, inplace=False)\n","                        )\n","                        (lora_A): ModuleDict(\n","                          (default): Linear(in_features=4096, out_features=32, bias=False)\n","                        )\n","                        (lora_B): ModuleDict(\n","                          (default): Linear(in_features=32, out_features=4096, bias=False)\n","                        )\n","                        (lora_embedding_A): ParameterDict()\n","                        (lora_embedding_B): ParameterDict()\n","                        (lora_magnitude_vector): ModuleDict()\n","                      )\n","                      (v_proj): lora.Linear8bitLt(\n","                        (base_layer): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n","                        (lora_dropout): ModuleDict(\n","                          (default): Dropout(p=0.05, inplace=False)\n","                        )\n","                        (lora_A): ModuleDict(\n","                          (default): Linear(in_features=4096, out_features=8, bias=False)\n","                        )\n","                        (lora_B): ModuleDict(\n","                          (default): Linear(in_features=8, out_features=4096, bias=False)\n","                        )\n","                        (lora_embedding_A): ParameterDict()\n","                        (lora_embedding_B): ParameterDict()\n","                        (lora_magnitude_vector): ModuleDict()\n","                      )\n","                      (o_proj): lora.Linear8bitLt(\n","                        (base_layer): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n","                        (lora_dropout): ModuleDict(\n","                          (default): Dropout(p=0.1, inplace=False)\n","                        )\n","                        (lora_A): ModuleDict(\n","                          (default): Linear(in_features=4096, out_features=32, bias=False)\n","                        )\n","                        (lora_B): ModuleDict(\n","                          (default): Linear(in_features=32, out_features=4096, bias=False)\n","                        )\n","                        (lora_embedding_A): ParameterDict()\n","                        (lora_embedding_B): ParameterDict()\n","                        (lora_magnitude_vector): ModuleDict()\n","                      )\n","                      (rotary_emb): LlamaRotaryEmbedding()\n","                    )\n","                    (mlp): LlamaMLP(\n","                      (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n","                      (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n","                      (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n","                      (act_fn): SiLU()\n","                    )\n","                    (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","                    (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","                  )\n","                )\n","                (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","                (rotary_emb): LlamaRotaryEmbedding()\n","              )\n","              (lm_head): Linear(in_features=4096, out_features=32016, bias=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":108}],"source":["model = PeftModel.from_pretrained(\n","    model,\n","    '/content/drive/MyDrive/CSCI_544/ANLP Project/repairllama-lora',\n","    # '/content/drive/MyDrive/CSCI_544/ANLP Project/finetuning/finetune-checkpoint-2400',\n","    # '/content/drive/MyDrive/CSCI_544/ANLP Project/finetuning/tokenise_change_checkpoint_400',\n","    torch_dtype=torch.float16,\n",")\n","model.config.pad_token = tokenizer.pad_token = tokenizer.unk_token\n","model.to(device)"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"GHQVDFGLfuwW","executionInfo":{"status":"ok","timestamp":1732606825814,"user_tz":480,"elapsed":4,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}}},"outputs":[],"source":["# Bug 05\n","\n","buggy_code5 = \"\"\"\n","correct the code below\n","    #include <stdio.h>\n","    #include <stdlib.h>\n","    int main(){\n","        int i,n,k;\n","        scanf(\"%d\",&n);\n","        char *str=(char*)malloc(n*sizeof(char));//dynamic memory allocation\n","        for(i=0;i<n;i++){\n","            scanf(\"%c\",*str[i]);\n","        }\n","      return 0;\n","    }\n","\"\"\""]},{"cell_type":"code","execution_count":110,"metadata":{"id":"XhLiRGQGfuwW","executionInfo":{"status":"ok","timestamp":1732606825815,"user_tz":480,"elapsed":4,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}}},"outputs":[],"source":["inputs = tokenizer(buggy_code5, return_tensors=\"pt\")\n","inputs_len = inputs[\"input_ids\"].shape[1]\n","inputs_ids = inputs[\"input_ids\"].to(device)"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"hAV8VHESfuwW","executionInfo":{"status":"ok","timestamp":1732606867736,"user_tz":480,"elapsed":41478,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}}},"outputs":[],"source":["generation_config = GenerationConfig(\n","    num_beams=10,\n","    early_stopping=True,\n","    # early_stopping=False,\n","    # length_penalty=-0.5  # extra line added\n",")\n","\n","outputs = model.generate(\n","    input_ids=inputs_ids,\n","    max_new_tokens=256,\n","    # max_new_tokens=2048,\n","    num_return_sequences=10,\n","    pad_token_id=tokenizer.pad_token_id,\n","    eos_token_id=tokenizer.eos_token_id,\n","    generation_config=generation_config,\n",")"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"08wosbTTfuwW","executionInfo":{"status":"ok","timestamp":1732606868763,"user_tz":480,"elapsed":6,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}}},"outputs":[],"source":["output_ids = outputs[:, inputs_len:]\n","output_patch = tokenizer.batch_decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"u6l3TI5ifuwX","executionInfo":{"status":"ok","timestamp":1732606868763,"user_tz":480,"elapsed":4,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a470632-bd66-4858-c188-ece545af0953"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char*)malloc(n*sizeof(char));//dynamic memory allocation\n","    for(i=0;i<n;i++){\n","        scanf(\"%c\",&str[i]);\n","    }\n","  return 0;\n","}\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char\n","-----------------\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char*)malloc(n*sizeof(char));//dynamic memory allocation\n","    for(i=0;i<n;i++){\n","        scanf(\"%c\",str[i]);\n","    }\n","  return 0;\n","}\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char*)malloc\n","-----------------\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char*)malloc(n*sizeof(\n","-----------------\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char*)malloc(n*sizeof\n","-----------------\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char*)malloc(\n","-----------------\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char*)malloc(n*\n","-----------------\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","    char *str=(char*)malloc\n","-----------------\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","int main(){\n","    int i,n,k;\n","    scanf(\"%d\",&n);\n","\n","-----------------\n","\n","\n","-----------------\n","\n","-----------------\n"]}],"source":["for each in output_patch:\n","    print(each)\n","    print('-----------------')"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Kq7jehOLfuwX","executionInfo":{"status":"ok","timestamp":1732603045285,"user_tz":480,"elapsed":5,"user":{"displayName":"Aabha Shailesh Pingle","userId":"14178069743854032177"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"84e5d9fe4311446b81df0aab813957c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a83431d2a90b45e1a21f5093c40f247e","IPY_MODEL_c4b9c53214f2462b90d5e1208b04789d","IPY_MODEL_a3c4729895cf415ab63a6c128690526d"],"layout":"IPY_MODEL_a6376f589205417788300744b52c6386"}},"a83431d2a90b45e1a21f5093c40f247e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_500cb46e6dd84877916c540b9cd4cee3","placeholder":"​","style":"IPY_MODEL_1131134d936241698dc62d461fadeb43","value":"Loading checkpoint shards: 100%"}},"c4b9c53214f2462b90d5e1208b04789d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa8bea870bb14817bc82e2cec9532e78","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1287cb0feb6344e5a54df94db285eac2","value":2}},"a3c4729895cf415ab63a6c128690526d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81a847a92b3a4b66836ac329062b29a3","placeholder":"​","style":"IPY_MODEL_b2b3b591220d497b9d670f987938fd1c","value":" 2/2 [01:13&lt;00:00, 34.27s/it]"}},"a6376f589205417788300744b52c6386":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"500cb46e6dd84877916c540b9cd4cee3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1131134d936241698dc62d461fadeb43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa8bea870bb14817bc82e2cec9532e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1287cb0feb6344e5a54df94db285eac2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81a847a92b3a4b66836ac329062b29a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2b3b591220d497b9d670f987938fd1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}