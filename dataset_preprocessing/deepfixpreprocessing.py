# -*- coding: utf-8 -*-
"""DeepfixPreprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G9BT0d-tuLe894nw80Jxr0yvI5jPEWW2
"""

from google.colab import drive
drive.mount('/content/drive')

import sqlite3
import csv
from difflib import SequenceMatcher

# Function to calculate similarity between two strings
def calculate_similarity(str1, str2):
    return SequenceMatcher(None, str1, str2).ratio()

# Connect to the SQLite database
db_path = "/content/drive/MyDrive/ANLPDatasets/deepfix/deepfix/data/iitk-dataset/dataset.db"
conn = sqlite3.connect(db_path)
cursor = conn.cursor()

# Query to fetch buggy code and all potential corrected codes
query = """
SELECT
    buggy.code_id AS ProblemID,
    buggy.code AS buggyCode,
    buggy.error AS BuggyError,
    corrected.code AS CorrectedCode,
    corrected.code_id AS CorrectedCodeID
FROM Code buggy
JOIN Code corrected
ON buggy.user_id = corrected.user_id
AND buggy.problem_id = corrected.problem_id
WHERE buggy.errorcount > 0
AND corrected.errorcount = 0
"""

cursor.execute(query)
rows = cursor.fetchall()

# Process the results to select the corrected code with the highest similarity
data = {}
for row in rows:
    problem_id, buggy_code, buggy_error, corrected_code, corrected_code_id = row

    # Group by ProblemID and BuggyCode
    key = (problem_id, buggy_code, buggy_error)
    if key not in data:
        data[key] = []
    data[key].append((corrected_code, corrected_code_id))

# Final dataset with the most similar corrected code
final_data = []
for (problem_id, buggy_code, buggy_error), corrected_entries in data.items():
    # Find the corrected code with the highest similarity
    best_match = max(corrected_entries, key=lambda x: calculate_similarity(buggy_code, x[0]))
    final_data.append((problem_id, buggy_code, buggy_error, best_match[0]))

# Output CSV file path
csv_file = "/content/drive/MyDrive/ANLPDatasets/buggy_corrected_similarity_dataset.csv"

with open(csv_file, mode='w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)

    writer.writerow(["ProblemID", "BuggyCode", "BuggyError", "CorrectedCode"])

    writer.writerows(final_data)

print(f"Dataset successfully created and saved to {csv_file}")

conn.close()

# Function to check if a program has only a single function
def has_single_function(source_code):
    # Use regex to find all function definitions
    functions = re.findall(r'\b(?:int|void|char|float|double|long|short)\s+\w+\s*\([^)]*\)\s*{', str(source_code))
    return len(functions) == 1 and 'struct' not in source_code

import pandas as pd
import re
input_path = '/content/drive/MyDrive/ANLPDatasets/buggy_corrected_similarity_dataset.csv'
data = pd.read_csv(input_path)

data['is_single_function_without_struct'] = data['BuggyCode'].apply(has_single_function)
filtered_data = data[data['is_single_function_without_struct']]

# Drop the helper column used for filtering
filtered_data = filtered_data.drop(columns=['is_single_function_without_struct'])

filtered_data.rename(columns={'BuggyCode': 'buggyCode', 'CorrectedCode': 'correctedCode'}, inplace=True)

filtered_data.insert(0, 'NewProblemID', range(1, len(filtered_data) + 1))

filtered_data = filtered_data[['NewProblemID', 'ProblemID', 'buggyCode', 'BuggyError', 'correctedCode']]

output_path = '/content/drive/MyDrive/ANLPDatasets/Deepfix_ProblemID_buggyCode_correctedCode.csv'
filtered_data.to_csv(output_path, index=False)

print(filtered_data.head())

filtered_data.shape

